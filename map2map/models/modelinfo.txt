
New model info
+------------------------------------------+------------+---------------------------------+
|                  Names                   | Parameters |              Shape              |
+------------------------------------------+------------+---------------------------------+
|            convblock0.weight             |    3072    |  torch.Size([512, 6, 1, 1, 1])  |
|             convblock0.bias              |    512     |        torch.Size([512])        |
|     convblock0.style_block.0.weight      |     6      |        torch.Size([6, 1])       |
|      convblock0.style_block.0.bias       |     6      |         torch.Size([6])         |
|               addnoise.std               |    512     |        torch.Size([512])        |
|           hblock0.conv1.weight           |  3538944   | torch.Size([256, 512, 3, 3, 3]) |
|            hblock0.conv1.bias            |    256     |        torch.Size([256])        |
|    hblock0.conv1.style_block.0.weight    |    512     |       torch.Size([512, 1])      |
|     hblock0.conv1.style_block.0.bias     |    512     |        torch.Size([512])        |
|          hblock0.addnoise1.std           |    256     |        torch.Size([256])        |
|           hblock0.conv2.weight           |  1769472   | torch.Size([256, 256, 3, 3, 3]) |
|            hblock0.conv2.bias            |    256     |        torch.Size([256])        |
|    hblock0.conv2.style_block.0.weight    |    256     |       torch.Size([256, 1])      |
|     hblock0.conv2.style_block.0.bias     |    256     |        torch.Size([256])        |
|          hblock0.addnoise2.std           |    256     |        torch.Size([256])        |
|           hblock0.proj.weight            |    1536    |  torch.Size([6, 256, 1, 1, 1])  |
|            hblock0.proj.bias             |     6      |         torch.Size([6])         |
|    hblock0.proj.style_block.0.weight     |    256     |       torch.Size([256, 1])      |
|     hblock0.proj.style_block.0.bias      |    256     |        torch.Size([256])        |
|        hblock0.noise_proj1.weight        |    1536    |  torch.Size([256, 6, 1, 1, 1])  |
|         hblock0.noise_proj1.bias         |    256     |        torch.Size([256])        |
| hblock0.noise_proj1.style_block.0.weight |     6      |        torch.Size([6, 1])       |
|  hblock0.noise_proj1.style_block.0.bias  |     6      |         torch.Size([6])         |
|        hblock0.noise_proj2.weight        |    1536    |  torch.Size([256, 6, 1, 1, 1])  |
|         hblock0.noise_proj2.bias         |    256     |        torch.Size([256])        |
| hblock0.noise_proj2.style_block.0.weight |     6      |        torch.Size([6, 1])       |
|  hblock0.noise_proj2.style_block.0.bias  |     6      |         torch.Size([6])         |
|           hblock1.conv1.weight           |   884736   | torch.Size([128, 256, 3, 3, 3]) |
|            hblock1.conv1.bias            |    128     |        torch.Size([128])        |
|    hblock1.conv1.style_block.0.weight    |    256     |       torch.Size([256, 1])      |
|     hblock1.conv1.style_block.0.bias     |    256     |        torch.Size([256])        |
|          hblock1.addnoise1.std           |    128     |        torch.Size([128])        |
|           hblock1.conv2.weight           |   442368   | torch.Size([128, 128, 3, 3, 3]) |
|            hblock1.conv2.bias            |    128     |        torch.Size([128])        |
|    hblock1.conv2.style_block.0.weight    |    128     |       torch.Size([128, 1])      |
|     hblock1.conv2.style_block.0.bias     |    128     |        torch.Size([128])        |
|          hblock1.addnoise2.std           |    128     |        torch.Size([128])        |
|           hblock1.proj.weight            |    768     |  torch.Size([6, 128, 1, 1, 1])  |
|            hblock1.proj.bias             |     6      |         torch.Size([6])         |
|    hblock1.proj.style_block.0.weight     |    128     |       torch.Size([128, 1])      |
|     hblock1.proj.style_block.0.bias      |    128     |        torch.Size([128])        |
|        hblock1.noise_proj1.weight        |    768     |  torch.Size([128, 6, 1, 1, 1])  |
|         hblock1.noise_proj1.bias         |    128     |        torch.Size([128])        |
| hblock1.noise_proj1.style_block.0.weight |     6      |        torch.Size([6, 1])       |
|  hblock1.noise_proj1.style_block.0.bias  |     6      |         torch.Size([6])         |
|        hblock1.noise_proj2.weight        |    768     |  torch.Size([128, 6, 1, 1, 1])  |
|         hblock1.noise_proj2.bias         |    128     |        torch.Size([128])        |
| hblock1.noise_proj2.style_block.0.weight |     6      |        torch.Size([6, 1])       |
|  hblock1.noise_proj2.style_block.0.bias  |     6      |         torch.Size([6])         |
|           hblock2.conv1.weight           |   221184   |  torch.Size([64, 128, 3, 3, 3]) |
|            hblock2.conv1.bias            |     64     |         torch.Size([64])        |
|    hblock2.conv1.style_block.0.weight    |    128     |       torch.Size([128, 1])      |
|     hblock2.conv1.style_block.0.bias     |    128     |        torch.Size([128])        |
|          hblock2.addnoise1.std           |     64     |         torch.Size([64])        |
|           hblock2.conv2.weight           |   110592   |  torch.Size([64, 64, 3, 3, 3])  |
|            hblock2.conv2.bias            |     64     |         torch.Size([64])        |
|    hblock2.conv2.style_block.0.weight    |     64     |       torch.Size([64, 1])       |
|     hblock2.conv2.style_block.0.bias     |     64     |         torch.Size([64])        |
|          hblock2.addnoise2.std           |     64     |         torch.Size([64])        |
|           hblock2.proj.weight            |    384     |   torch.Size([6, 64, 1, 1, 1])  |
|            hblock2.proj.bias             |     6      |         torch.Size([6])         |
|    hblock2.proj.style_block.0.weight     |     64     |       torch.Size([64, 1])       |
|     hblock2.proj.style_block.0.bias      |     64     |         torch.Size([64])        |
|        hblock2.noise_proj1.weight        |    384     |   torch.Size([64, 6, 1, 1, 1])  |
|         hblock2.noise_proj1.bias         |     64     |         torch.Size([64])        |
| hblock2.noise_proj1.style_block.0.weight |     6      |        torch.Size([6, 1])       |
|  hblock2.noise_proj1.style_block.0.bias  |     6      |         torch.Size([6])         |
|        hblock2.noise_proj2.weight        |    384     |   torch.Size([64, 6, 1, 1, 1])  |
|         hblock2.noise_proj2.bias         |     64     |         torch.Size([64])        |
| hblock2.noise_proj2.style_block.0.weight |     6      |        torch.Size([6, 1])       |
|  hblock2.noise_proj2.style_block.0.bias  |     6      |         torch.Size([6])         |
|            noise_proj.weight             |    3072    |  torch.Size([512, 6, 1, 1, 1])  |
|             noise_proj.bias              |    512     |        torch.Size([512])        |
|     noise_proj.style_block.0.weight      |     6      |        torch.Size([6, 1])       |
|      noise_proj.style_block.0.bias       |     6      |         torch.Size([6])         |
+------------------------------------------+------------+---------------------------------+
Total Trainable Params: 6989426

+---------------------------------------+------------+---------------------------------+
|                 Names                 | Parameters |              Shape              |
+---------------------------------------+------------+---------------------------------+
|            block0.0.weight            |    3072    |  torch.Size([512, 6, 1, 1, 1])  |
|             block0.0.bias             |    512     |        torch.Size([512])        |
|     block0.0.style_block.0.weight     |     6      |        torch.Size([6, 1])       |
|      block0.0.style_block.0.bias      |     6      |         torch.Size([6])         |
|     blocks.0.noise_upsample.0.std     |    512     |        torch.Size([512])        |
|         blocks.0.conv.0.weight        |  3538944   | torch.Size([256, 512, 3, 3, 3]) |
|          blocks.0.conv.0.bias         |    256     |        torch.Size([256])        |
|  blocks.0.conv.0.style_block.0.weight |    512     |       torch.Size([512, 1])      |
|   blocks.0.conv.0.style_block.0.bias  |    512     |        torch.Size([512])        |
|         blocks.0.addnoise.std         |    256     |        torch.Size([256])        |
|        blocks.0.conv1.0.weight        |  1769472   | torch.Size([256, 256, 3, 3, 3]) |
|         blocks.0.conv1.0.bias         |    256     |        torch.Size([256])        |
| blocks.0.conv1.0.style_block.0.weight |    256     |       torch.Size([256, 1])      |
|  blocks.0.conv1.0.style_block.0.bias  |    256     |        torch.Size([256])        |
|         blocks.0.proj.0.weight        |    1536    |  torch.Size([6, 256, 1, 1, 1])  |
|          blocks.0.proj.0.bias         |     6      |         torch.Size([6])         |
|  blocks.0.proj.0.style_block.0.weight |    256     |       torch.Size([256, 1])      |
|   blocks.0.proj.0.style_block.0.bias  |    256     |        torch.Size([256])        |
|     blocks.1.noise_upsample.0.std     |    256     |        torch.Size([256])        |
|         blocks.1.conv.0.weight        |   884736   | torch.Size([128, 256, 3, 3, 3]) |
|          blocks.1.conv.0.bias         |    128     |        torch.Size([128])        |
|  blocks.1.conv.0.style_block.0.weight |    256     |       torch.Size([256, 1])      |
|   blocks.1.conv.0.style_block.0.bias  |    256     |        torch.Size([256])        |
|         blocks.1.addnoise.std         |    128     |        torch.Size([128])        |
|        blocks.1.conv1.0.weight        |   442368   | torch.Size([128, 128, 3, 3, 3]) |
|         blocks.1.conv1.0.bias         |    128     |        torch.Size([128])        |
| blocks.1.conv1.0.style_block.0.weight |    128     |       torch.Size([128, 1])      |
|  blocks.1.conv1.0.style_block.0.bias  |    128     |        torch.Size([128])        |
|         blocks.1.proj.0.weight        |    768     |  torch.Size([6, 128, 1, 1, 1])  |
|          blocks.1.proj.0.bias         |     6      |         torch.Size([6])         |
|  blocks.1.proj.0.style_block.0.weight |    128     |       torch.Size([128, 1])      |
|   blocks.1.proj.0.style_block.0.bias  |    128     |        torch.Size([128])        |
|     blocks.2.noise_upsample.0.std     |    128     |        torch.Size([128])        |
|         blocks.2.conv.0.weight        |   221184   |  torch.Size([64, 128, 3, 3, 3]) |
|          blocks.2.conv.0.bias         |     64     |         torch.Size([64])        |
|  blocks.2.conv.0.style_block.0.weight |    128     |       torch.Size([128, 1])      |
|   blocks.2.conv.0.style_block.0.bias  |    128     |        torch.Size([128])        |
|         blocks.2.addnoise.std         |     64     |         torch.Size([64])        |
|        blocks.2.conv1.0.weight        |   110592   |  torch.Size([64, 64, 3, 3, 3])  |
|         blocks.2.conv1.0.bias         |     64     |         torch.Size([64])        |
| blocks.2.conv1.0.style_block.0.weight |     64     |       torch.Size([64, 1])       |
|  blocks.2.conv1.0.style_block.0.bias  |     64     |         torch.Size([64])        |
|         blocks.2.proj.0.weight        |    384     |   torch.Size([6, 64, 1, 1, 1])  |
|          blocks.2.proj.0.bias         |     6      |         torch.Size([6])         |
|  blocks.2.proj.0.style_block.0.weight |     64     |       torch.Size([64, 1])       |
|   blocks.2.proj.0.style_block.0.bias  |     64     |         torch.Size([64])        |
+---------------------------------------+------------+---------------------------------+
Total Trainable Params: 6979422
